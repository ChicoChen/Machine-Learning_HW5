{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "import torchvision.transforms as trans\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "path define block\n",
    "'''\n",
    "TRAIN_PATH = \"train\"\n",
    "TEST_PATH = \"test\"\n",
    "#device = \"cuda\"\n",
    "device = torch.device(\"cuda\", 1)\n",
    "data_multiple = 5\n",
    "# try device = \"cuda\" \n",
    "# and change your settings/accelerator to GPU if you want it to run faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "self-define dataset \n",
    "'''\n",
    "class multi_Dataset(Dataset):\n",
    "    def __init__(self, data, root, return_filename=False, len = 1):\n",
    "        self.data = data\n",
    "        self.return_filename = return_filename\n",
    "        self.root = root\n",
    "        self.len = len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        filename, label, ID = self.data[index]\n",
    "\n",
    "        label_code = []\n",
    "        for character in label:\n",
    "            if(character.isalpha()):label_code.append(ord(character)- ord('a') + 10)\n",
    "            else: label_code.append(int(character))\n",
    "\n",
    "        img = cv2.imread(f\"{self.root}/{filename}\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (64,64))\n",
    "        #img = np.mean(img, axis=2) # take the means of color\n",
    "        process = trans.Compose([\n",
    "                            trans.ToTensor(), \n",
    "\t                        trans.Normalize(mean = [0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                            ])\n",
    "        img = process(img)\n",
    "        if self.return_filename:\n",
    "            img = trans.functional.rotate(img, (random.randint(0,data_multiple-1) - data_multiple/2)*10, fill = 255)\n",
    "            return img, filename\n",
    "        else:\n",
    "            img = trans.functional.rotate(img, (ID-data_multiple/2)*10, fill = 255)\n",
    "            #plt.imshow(  img.permute(1, 2, 0)  )\n",
    "            return img, label_code\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "task1 model\n",
    "'''\n",
    "class task1_Resnet50(torchvision.models.resnet.ResNet):\n",
    "    def __init__(self):\n",
    "        # Pass default resnet50 arguments to super init\n",
    "        # https://github.com/pytorch/vision/blob/e130c6cca88160b6bf7fea9b8bc251601a1a75c5/torchvision/models/resnet.py#L260\n",
    "        super(task1_Resnet50, self).__init__(torchvision.models.resnet.Bottleneck, [3, 4, 6, 3])\n",
    "        self.load_state_dict(torchvision.models.resnet50(pretrained=True).state_dict())\n",
    "        self.mylayer1 = nn.Linear(2048, 512)\n",
    "        self.mylayer2 = nn.Linear(512, 10)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.mylayer1(x)\n",
    "        x = self.mylayer2(x)\n",
    "\n",
    "        return [x]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "task2 model\n",
    "'''\n",
    "class task2_Resnet50(torchvision.models.resnet.ResNet):\n",
    "    def __init__(self, pretrained=True, len = 2):\n",
    "        # Pass default resnet50 arguments to super init\n",
    "        # https://github.com/pytorch/vision/blob/e130c6cca88160b6bf7fea9b8bc251601a1a75c5/torchvision/models/resnet.py#L260\n",
    "        super(task2_Resnet50, self).__init__(torchvision.models.resnet.Bottleneck, [3, 4, 6, 3])\n",
    "        self.load_state_dict(torchvision.models.resnet50(pretrained=True).state_dict())\n",
    "        self.mylayer1 = nn.Linear(2048, 512)\n",
    "        self.len = len\n",
    "        self.mylayer2A = nn.Linear(512, 36)\n",
    "        self.mylayer2B = nn.Linear(512, 36)\n",
    "        \n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.mylayer1(x)\n",
    "        x1 = self.mylayer2A(x)\n",
    "        x2 = self.mylayer2B(x)\n",
    "\n",
    "        return [x1, x2]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "task3 model\n",
    "'''\n",
    "class task3_Resnet50(torchvision.models.resnet.ResNet):\n",
    "    def __init__(self, pretrained=True, len = 2):\n",
    "        # Pass default resnet50 arguments to super init\n",
    "        # https://github.com/pytorch/vision/blob/e130c6cca88160b6bf7fea9b8bc251601a1a75c5/torchvision/models/resnet.py#L260\n",
    "        super(task3_Resnet50, self).__init__(torchvision.models.resnet.Bottleneck, [3, 4, 6, 3])\n",
    "        self.load_state_dict(torchvision.models.resnet50(pretrained=True).state_dict())\n",
    "        self.mylayer1 = nn.Linear(2048, 512)\n",
    "        self.len = len\n",
    "        self.mylayer2A = nn.Linear(512, 36)\n",
    "        self.mylayer2B = nn.Linear(512, 36)\n",
    "        self.mylayer2C = nn.Linear(512, 36)\n",
    "        self.mylayer2D = nn.Linear(512, 36)\n",
    "        '''\n",
    "        self.mylayerA = nn.Linear(512, 36)\n",
    "        self.mylayerB = nn.Linear(512, 36)\n",
    "        '''\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.mylayer1(x)\n",
    "        x1 = self.mylayer2A(x)\n",
    "        x2 = self.mylayer2B(x)\n",
    "        x3 = self.mylayer2C(x)\n",
    "        x4 = self.mylayer2D(x)\n",
    "\n",
    "        return [x1, x2, x3, x4]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\colding\\virtualenv\\ML_HW5\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\colding\\virtualenv\\ML_HW5\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\R5 3600/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d7bec26a564904adaebe44ee37491f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mmodel inference block\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m      5\u001b[0m test_model \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m3\u001b[39m\n\u001b[1;32m----> 6\u001b[0m test_model[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m task1_Resnet50()\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m      7\u001b[0m test_model[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m task2_Resnet50(\u001b[39mlen\u001b[39m \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mto(device) \n\u001b[0;32m      8\u001b[0m test_model[\u001b[39m2\u001b[39m] \u001b[39m=\u001b[39m task3_Resnet50(\u001b[39mlen\u001b[39m \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m)\u001b[39m.\u001b[39mto(device) \n",
      "File \u001b[1;32md:\\colding\\virtualenv\\ML_HW5\\lib\\site-packages\\torch\\nn\\modules\\module.py:987\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    984\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m    985\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 987\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[1;32md:\\colding\\virtualenv\\ML_HW5\\lib\\site-packages\\torch\\nn\\modules\\module.py:639\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    638\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 639\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    641\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    642\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    643\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    644\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    650\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32md:\\colding\\virtualenv\\ML_HW5\\lib\\site-packages\\torch\\nn\\modules\\module.py:662\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    659\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    660\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    661\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 662\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    663\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    664\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32md:\\colding\\virtualenv\\ML_HW5\\lib\\site-packages\\torch\\nn\\modules\\module.py:985\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    982\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m    983\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    984\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 985\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "File \u001b[1;32md:\\colding\\virtualenv\\ML_HW5\\lib\\site-packages\\torch\\cuda\\__init__.py:221\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    218\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 221\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    222\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    224\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "'''\n",
    "model inference block\n",
    "'''\n",
    "\n",
    "test_model = [0]*3\n",
    "test_model[0] = task1_Resnet50().to(device)\n",
    "test_model[1] = task2_Resnet50(len = 2).to(device) \n",
    "test_model[2] = task3_Resnet50(len = 4).to(device) \n",
    "\n",
    "test_model[0].load_state_dict(torch.load(f'109550110/task1_model_1.pt'))\n",
    "test_model[1].load_state_dict(torch.load(f'109550110/task2_model_1.pt'))\n",
    "test_model[2].load_state_dict(torch.load(f'109550110/task3_model_1.pt'))\n",
    "\n",
    "test_model[0].eval()\n",
    "test_model[1].eval()\n",
    "test_model[2].eval()\n",
    "\n",
    "test_data = []\n",
    "with open(f'{TEST_PATH}/../sample_submission.csv', newline='') as csvfile:\n",
    "    for row in csv.reader(csvfile, delimiter=','):\n",
    "      if(row[0] == \"filename\"): continue\n",
    "      test_data.append(row + [-1])  \n",
    "\n",
    "test_ds_1 = multi_Dataset([data for data in test_data if data[0].startswith(\"task1\")], root=TEST_PATH, return_filename=True,  len = 1)\n",
    "test_dl_1 = DataLoader(test_ds_1, batch_size=500, num_workers=1, drop_last=False, shuffle=False)\n",
    "\n",
    "test_ds_2 = multi_Dataset([data for data in test_data if data[0].startswith(\"task2\")], root=TEST_PATH, return_filename=True, len = 2)\n",
    "test_dl_2 = DataLoader(test_ds_2, batch_size=500, num_workers=1, drop_last=False, shuffle=False)\n",
    "\n",
    "test_ds_3 = multi_Dataset([data for data in test_data if data[0].startswith(\"task3\")], root=TEST_PATH, return_filename=True,  len = 4)\n",
    "test_dl_3 = DataLoader(test_ds_3, batch_size=500, num_workers=1, drop_last=False, shuffle=False)\n",
    "\n",
    "if os.path.exists('submission.csv'):\n",
    "    csv_writer = csv.writer(open('109550110_submission.csv', 'w', newline=''))\n",
    "else:\n",
    "    csv_writer = csv.writer(open('109550110_submission.csv', 'w', newline=''))\n",
    "csv_writer.writerow([\"filename\", \"label\"])\n",
    "\n",
    "for j, dl in enumerate([test_dl_1, test_dl_2, test_dl_3]):\n",
    "    print(j)\n",
    "    for image, filenames in dl:\n",
    "        image = image.to(device)\n",
    "        pred = test_model[j](image)\n",
    "        for i, p in enumerate(pred):\n",
    "            pred[i] = torch.argmax(p, dim=1)\n",
    "\n",
    "        #print(len(filenames))\n",
    "        for i in range(len(filenames)):\n",
    "            answer = ''\n",
    "            for p in pred:\n",
    "                if(p[i].item() >= 10): answer += str(chr(p[i].item() - 10 + ord('a')))\n",
    "                else: answer += str(p[i].item())\n",
    "            csv_writer.writerow([filenames[i], answer])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_HW5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7894b3cb23251d502d1cfea2dd06244056e0aace376e5aac2e9d98cee4a2396"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
