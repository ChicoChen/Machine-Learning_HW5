{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "import torchvision.transforms as trans\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "path define block\n",
    "'''\n",
    "TRAIN_PATH = \"train\"\n",
    "TEST_PATH = \"test\"\n",
    "#device = \"cuda\"\n",
    "device = torch.device(\"cuda\", 1)\n",
    "data_multiple = 5\n",
    "# try device = \"cuda\" \n",
    "# and change your settings/accelerator to GPU if you want it to run faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "self-define dataset \n",
    "'''\n",
    "class multi_Dataset(Dataset):\n",
    "    def __init__(self, data, root, return_filename=False, len = 1):\n",
    "        self.data = data\n",
    "        self.return_filename = return_filename\n",
    "        self.root = root\n",
    "        self.len = len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        filename, label, ID = self.data[index]\n",
    "\n",
    "        label_code = []\n",
    "        for character in label:\n",
    "            if(character.isalpha()):label_code.append(ord(character)- ord('a') + 10)\n",
    "            else: label_code.append(int(character))\n",
    "\n",
    "        img = cv2.imread(f\"{self.root}/{filename}\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (64,64))\n",
    "        #img = np.mean(img, axis=2) # take the means of color\n",
    "        process = trans.Compose([\n",
    "                            trans.ToTensor(), \n",
    "\t                        trans.Normalize(mean = [0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                            ])\n",
    "        img = process(img)\n",
    "        if self.return_filename:\n",
    "            img = trans.functional.rotate(img, (random.randint(0,data_multiple-1) - data_multiple/2)*10, fill = 255)\n",
    "            return img, filename\n",
    "        else:\n",
    "            img = trans.functional.rotate(img, (ID-data_multiple/2)*10, fill = 255)\n",
    "            #plt.imshow(  img.permute(1, 2, 0)  )\n",
    "            return img, label_code\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dataset division block\n",
    "'''\n",
    "task1_train = []\n",
    "task2_train = []\n",
    "task3_train = []\n",
    "task1_val = []\n",
    "task2_val = []\n",
    "task3_val = []\n",
    "\n",
    "with open(f'{TRAIN_PATH}/annotations.csv', newline='') as csvfile:\n",
    "  for row in csv.reader(csvfile, delimiter=','):\n",
    "    for i in range(data_multiple):\n",
    "      row_i = row + [i]\n",
    "      if(row[0].startswith(\"task1\")):\n",
    "          if random.random() < 0.7: task1_train.append(row_i)\n",
    "          else: task1_val.append(row_i)\n",
    "      elif(row[0].startswith(\"task2\")):\n",
    "          if random.random() < 0.7: task2_train.append(row_i)\n",
    "          else: task2_val.append(row_i)\n",
    "      elif(row[0].startswith(\"task3\")):\n",
    "          if random.random() < 0.7: task3_train.append(row_i)\n",
    "          else: task3_val.append(row_i)\n",
    "\n",
    "task1_ds = multi_Dataset(task1_train, root=TRAIN_PATH, len = 1)\n",
    "task1_dl = DataLoader(task1_ds, batch_size=500, num_workers=1, drop_last=True, shuffle=True)\n",
    "task1_val_ds = multi_Dataset(task1_val, root=TRAIN_PATH, len = 1)\n",
    "task1_val_dl = DataLoader(task1_val_ds, batch_size=500, num_workers=1, drop_last=False, shuffle=False)\n",
    "\n",
    "task2_ds = multi_Dataset(task2_train, root=TRAIN_PATH, len = 2)\n",
    "task2_dl = DataLoader(task2_ds, batch_size=500, num_workers=1, drop_last=True, shuffle=True)\n",
    "task2_val_ds = multi_Dataset(task2_val, root=TRAIN_PATH, len = 2)\n",
    "task2_val_dl = DataLoader(task2_val_ds, batch_size=500, num_workers=1, drop_last=False, shuffle=False)\n",
    "\n",
    "task3_ds = multi_Dataset(task3_train, root=TRAIN_PATH, len = 4)\n",
    "task3_dl = DataLoader(task3_ds, batch_size=500, num_workers=1, drop_last=True, shuffle=True)\n",
    "task3_val_ds = multi_Dataset(task3_val, root=TRAIN_PATH, len = 4)\n",
    "task3_val_dl = DataLoader(task3_val_ds, batch_size=500, num_workers=1, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "define model_train function\n",
    "'''\n",
    "def model_train(model, model_name, dl, val, label_len, epoch):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    max_acc = 0\n",
    "    for e in range(epoch):\n",
    "        print(f\"Epoch [{e}]\")\n",
    "        model.train()\n",
    "\n",
    "        for image, label in dl:\n",
    "            image = image.to(device)\n",
    "            for i in range(label_len):label[i] = label[i].to(device)\n",
    "            pred = model(image)\n",
    "            #print(pred[0].shape)\n",
    "            #print(pred)\n",
    "            #print(label[0].shape)\n",
    "\n",
    "            for i in range(label_len):\n",
    "                if(i == 0): loss = loss_fn(pred[i], label[i])\n",
    "                else: loss += loss_fn(pred[i], label[i])\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        sample_count = 0\n",
    "        correct_count = 0\n",
    "        temp = 0\n",
    "        for image, label in val:\n",
    "            image = image.to(device)\n",
    "            for i in range(label_len):label[i] = label[i].to(device)\n",
    "            pred = model(image)\n",
    "            \n",
    "            \n",
    "            for i in range(label_len):\n",
    "                if(i == 0): loss = loss_fn(pred[i], label[i])\n",
    "                else: loss += loss_fn(pred[i], label[i])\n",
    "                pred[i] = torch.argmax(pred[i], dim=1)\n",
    "            #print(pred[0].shape) # torch.Size([5000])\n",
    "            #print(label[0].shape) # torch.Size([5000])\n",
    "            \n",
    "            sample_count += len(image)\n",
    "            if (label_len == 1): correct_count += (label[0] == pred[0]).sum()\n",
    "            else:\n",
    "                temp += (label[0] == pred[0]).sum()\n",
    "                count = (label[0] == pred[0])\n",
    "                for i in range(label_len)[1:]:\n",
    "                    count= count * (label[i] == pred[i])\n",
    "                correct_count += count.sum()\n",
    "            \n",
    "        print(\"accuracy (validation):\", correct_count / sample_count)\n",
    "        if correct_count / sample_count> max_acc:\n",
    "            max_acc = correct_count / sample_count\n",
    "            torch.save(model.state_dict(), f'109550110/' + model_name)\n",
    "            print(\"model_save: \" + str(e))\n",
    "        print(\"accuracy (validation):\", temp / sample_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "task1 model\n",
    "'''\n",
    "class task1_Resnet50(torchvision.models.resnet.ResNet):\n",
    "    def __init__(self):\n",
    "        # Pass default resnet50 arguments to super init\n",
    "        # https://github.com/pytorch/vision/blob/e130c6cca88160b6bf7fea9b8bc251601a1a75c5/torchvision/models/resnet.py#L260\n",
    "        super(task1_Resnet50, self).__init__(torchvision.models.resnet.Bottleneck, [3, 4, 6, 3])\n",
    "        self.load_state_dict(torchvision.models.resnet50(pretrained=True).state_dict())\n",
    "        self.mylayer1 = nn.Linear(2048, 512)\n",
    "        self.mylayer2 = nn.Linear(512, 10)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.mylayer1(x)\n",
    "        x = self.mylayer2(x)\n",
    "\n",
    "        return [x]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "task2 model\n",
    "'''\n",
    "class task2_Resnet50(torchvision.models.resnet.ResNet):\n",
    "    def __init__(self, pretrained=True, len = 2):\n",
    "        # Pass default resnet50 arguments to super init\n",
    "        # https://github.com/pytorch/vision/blob/e130c6cca88160b6bf7fea9b8bc251601a1a75c5/torchvision/models/resnet.py#L260\n",
    "        super(task2_Resnet50, self).__init__(torchvision.models.resnet.Bottleneck, [3, 4, 6, 3])\n",
    "        self.load_state_dict(torchvision.models.resnet50(pretrained=True).state_dict())\n",
    "        self.mylayer1 = nn.Linear(2048, 512)\n",
    "        self.len = len\n",
    "        self.mylayer2A = nn.Linear(512, 36)\n",
    "        self.mylayer2B = nn.Linear(512, 36)\n",
    "        \n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.mylayer1(x)\n",
    "        x1 = self.mylayer2A(x)\n",
    "        x2 = self.mylayer2B(x)\n",
    "\n",
    "        return [x1, x2]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "task3 model\n",
    "'''\n",
    "class task3_Resnet50(torchvision.models.resnet.ResNet):\n",
    "    def __init__(self, pretrained=True, len = 2):\n",
    "        # Pass default resnet50 arguments to super init\n",
    "        # https://github.com/pytorch/vision/blob/e130c6cca88160b6bf7fea9b8bc251601a1a75c5/torchvision/models/resnet.py#L260\n",
    "        super(task3_Resnet50, self).__init__(torchvision.models.resnet.Bottleneck, [3, 4, 6, 3])\n",
    "        self.load_state_dict(torchvision.models.resnet50(pretrained=True).state_dict())\n",
    "        self.mylayer1 = nn.Linear(2048, 512)\n",
    "        self.len = len\n",
    "        self.mylayer2A = nn.Linear(512, 36)\n",
    "        self.mylayer2B = nn.Linear(512, 36)\n",
    "        self.mylayer2C = nn.Linear(512, 36)\n",
    "        self.mylayer2D = nn.Linear(512, 36)\n",
    "        '''\n",
    "        self.mylayerA = nn.Linear(512, 36)\n",
    "        self.mylayerB = nn.Linear(512, 36)\n",
    "        '''\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.mylayer1(x)\n",
    "        x1 = self.mylayer2A(x)\n",
    "        x2 = self.mylayer2B(x)\n",
    "        x3 = self.mylayer2C(x)\n",
    "        x4 = self.mylayer2D(x)\n",
    "\n",
    "        return [x1, x2, x3, x4]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model training block\n",
    "(model will be saved in floder \"/109550110\", be aware that the models will be save by model_train function)\n",
    "'''\n",
    "\n",
    "task1_model = task1_Resnet50().to(device) \n",
    "model_train(task1_model, 'task1_model_1.pt', task1_dl, task1_val_dl, 1, 30)\n",
    "\n",
    "task2_model = task2_Resnet50(len = 2).to(device) \n",
    "model_train(task2_model, 'task2_model_1.pt', task2_dl, task2_val_dl, 2, 50)\n",
    "\n",
    "task3_model = task3_Resnet50(len = 4).to(device) \n",
    "model_train(task3_model, 'task3_model_1.pt', task3_dl, task3_val_dl, 4, 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_HW5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7894b3cb23251d502d1cfea2dd06244056e0aace376e5aac2e9d98cee4a2396"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
